Apache Spark  Vs DataBricks



1.Apache Spark is a Open -source  distributed processing framework Whereas Databricks is  a campany they have a product also called as a databricks.
Apache Spark has Two layers :=

1.Spark Core
2.High level of API

1.Spark Core :- underneath layer is a spark core, language are  SCALA ,JAVA,PYTHON,R . when you work with spark core you work with the rdd level 
RDD:= RESILIENT DISTRIBUTED DATASETS and  and is a fundamental data structure in Spark.
It doesn't have any schema and can hold any type of data, providing low-level, fine-grained control over data manipulation. 
RDDs are immutable distributed collections of objects that process across a cluster of machines.


2.High level of API :- above the spark core we have a higher level of API's


ðŸ”¹ RDD: RDD stands for Resilient Distributed Dataset and is a fundamental data structure in Spark.
It doesn't have any schema and can hold any type of data, providing low-level, fine-grained control over data manipulation.
RDDs are immutable distributed collections of objects that process across a cluster of machines.

ðŸ”¹ DataFrame: A data frame is a distributed collection of data that has a schema (column names and data types) attached to it.
A data frame provides a higher-level abstraction than an RDD and is designed to handle structured and semi-structured data.

ðŸ”¹ Datasets: Datasets are an extension of DataFrames and are language-specific.
They provide a higher-level API with strongly-typed, object-oriented programming features like Java and Scala, while still benefiting from Spark optimizations.
Datasets combine the best features of RDDs and DataFrames.





